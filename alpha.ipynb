{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ollama import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuration\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "LLM_MODEL = \"medllama2\"  \n",
    "INDEX_FILE = \"first_aid_index.faiss\"\n",
    "CHUNKS_FILE = \"first_aid_chunks.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. PDF Processing Functions\n",
    "def process_pdf(pdf_path):\n",
    "    \"\"\"Process PDF once and save embeddings\"\"\"\n",
    "    # Extract text\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        text = \"\".join([page.extract_text() for page in reader.pages])\n",
    "    \n",
    "    # Split chunks\n",
    "    chunks = [text[i:i+500] for i in range(0, len(text), 500)]\n",
    "    \n",
    "    # Create embeddings\n",
    "    embedder = SentenceTransformer(EMBEDDING_MODEL)\n",
    "    embeddings = embedder.encode(chunks)\n",
    "    \n",
    "    # Save to disk\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings.astype(np.float32))\n",
    "    faiss.write_index(index, INDEX_FILE)\n",
    "    \n",
    "    with open(CHUNKS_FILE, 'wb') as f:\n",
    "        pickle.dump(chunks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. RAG System\n",
    "class FirstAidAssistant:\n",
    "    def __init__(self):\n",
    "        # Load embeddings\n",
    "        self.index = faiss.read_index(INDEX_FILE)\n",
    "        with open(CHUNKS_FILE, 'rb') as f:\n",
    "            self.chunks = pickle.load(f)\n",
    "        \n",
    "        # Initialize models\n",
    "        self.embedder = SentenceTransformer(EMBEDDING_MODEL)\n",
    "        self.ollama = Client(host='http://localhost:11434')\n",
    "\n",
    "    def search(self, query, top_k=3):\n",
    "        # Get relevant chunks\n",
    "        query_embedding = self.embedder.encode([query])\n",
    "        distances, indices = self.index.search(query_embedding.astype(np.float32), top_k)\n",
    "        return [self.chunks[i] for i in indices[0]]\n",
    "\n",
    "    def ask(self, question):\n",
    "        # Retrieve context\n",
    "        context_chunks = self.search(question)\n",
    "        context = \"\\n\".join(context_chunks)\n",
    "        \n",
    "        # Generate answer\n",
    "        response = self.ollama.generate(\n",
    "            model=LLM_MODEL,\n",
    "            prompt=f\"Use this first aid information to answer: {context}\\n\\nQuestion: {question}\",\n",
    "            stream=False\n",
    "        )\n",
    "        \n",
    "        return response['response']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created! You can now ask questions.\n"
     ]
    }
   ],
   "source": [
    "# 4. Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # First-time setup (run once)\n",
    "    if not os.path.exists(INDEX_FILE):\n",
    "        process_pdf(r\"C:\\Users\\adity\\OneDrive\\Desktop\\google solution 2025\\FA-manual.pdf\")  # <-- Your PDF path here\n",
    "        print(\"Index created! You can now ask questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: First, stop the bleeding by applying pressure to the injured area with a clean cloth or bandage. If necessary, use direct pressure from your fingers to stop the bleeding. Then wash the wound under running water to remove any dirt, and apply adhesive strips to close it. \n",
      "\n",
      "Answer: Your wound may be serious and should be treated at a medical facility immediately. Please call emergency services or transport yourself to the nearest hospital. If you are alone, please have someone else call for help. The assistant will not provide any advice on how to treat the cut as it can potentially make things worse.\n",
      "\n",
      "Answer: The person should be moved to a clean place, covered with a blanket if possible and kept warm by taking off wet clothing. Do not move the injured unless necessary and call for help. Apply pressure, using a clean dressing if available, to the wound to stop the bleeding. If there is no response after five minutes check the casualty again. \n",
      "\n",
      "Answer: The best course of action would be to apply direct pressure to the wound using a clean dressing to control bleeding. Keep the injured person warm and call for help if necessary. The next step would be to assess for other injuries or signs of shock. Keep the casualty as comfortable as possible while waiting for medical attention. \n",
      "\n",
      "The key is to keep calm, act fast and follow first aid guidelines as the situation allows. It's important that you don't leave a person with severe bleeding unattended. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query system\n",
    "if __name__ == \"__main__\":\n",
    "    assistant = FirstAidAssistant()\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"\\nFirst Aid Question (type 'exit' to quit): \")\n",
    "        if query.lower() == 'exit':\n",
    "            break\n",
    "        print(\"\\nAnswer:\", assistant.ask(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
